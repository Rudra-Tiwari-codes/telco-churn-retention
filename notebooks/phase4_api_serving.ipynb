{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 4: API Serving & Deployment\n",
    "\n",
    "This notebook demonstrates the API serving layer for the Telco Churn Prediction system, focusing on:\n",
    "\n",
    "1. **API Setup**: Starting and configuring the FastAPI service\n",
    "2. **Endpoint Testing**: Testing all API endpoints (health, metadata, predict)\n",
    "3. **Prediction Examples**: Making single and batch predictions\n",
    "4. **SHAP Explanations**: Verifying explainability in API responses\n",
    "5. **Integration Testing**: End-to-end testing of the prediction pipeline\n",
    "\n",
    "## Objectives\n",
    "- Verify API service functionality\n",
    "- Test prediction accuracy and consistency\n",
    "- Validate SHAP explanations\n",
    "- Ensure production readiness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: C:\\Users\\tiwar\\OneDrive - The University of Melbourne\\Desktop\\New folder\\telco-churn-retention\n"
     ]
    }
   ],
   "source": [
    "# Simple setup for API testing\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Find project root\n",
    "PROJECT_ROOT = Path().resolve().parent if (Path().resolve().parent / 'src').exists() else Path().resolve()\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Libraries imported\n"
     ]
    }
   ],
   "source": [
    "# Import libraries for API testing\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from rich.console import Console\n",
    "from rich.table import Table\n",
    "\n",
    "console = Console()\n",
    "print(\"[OK] Libraries imported\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Verify Prerequisites\n",
    "\n",
    "Before testing the API, we need to ensure:\n",
    "- Models have been trained (Phase 3 completed)\n",
    "- Feature pipeline has been saved\n",
    "- API service can be started\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;36mChecking Prerequisites...\u001b[0m\n",
      "\u001b[32m[OK] Models found: 20251129T094943Z\u001b[0m\n",
      "  - Model files: 1\n",
      "  - Pipeline files: 1\n",
      "\u001b[32m[OK] Processed data found: 5 versions\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Check if models exist\n",
    "models_dir = PROJECT_ROOT / \"models\"\n",
    "processed_dir = PROJECT_ROOT / \"data\" / \"processed\"\n",
    "\n",
    "console.print(\"\\n[bold cyan]Checking Prerequisites...[/bold cyan]\")\n",
    "\n",
    "# Check models\n",
    "if models_dir.exists():\n",
    "    model_dirs = [d for d in models_dir.iterdir() if d.is_dir()]\n",
    "    if model_dirs:\n",
    "        latest_model_dir = max(model_dirs, key=lambda p: p.name)\n",
    "        console.print(f\"[green][OK] Models found: {latest_model_dir}[/green]\")\n",
    "        \n",
    "        # Check for model files\n",
    "        model_files = list(latest_model_dir.rglob(\"*_model.pkl\"))\n",
    "        pipeline_files = list(latest_model_dir.rglob(\"feature_pipeline.pkl\"))\n",
    "        \n",
    "        console.print(f\"  - Model files: {len(model_files)}\")\n",
    "        console.print(f\"  - Pipeline files: {len(pipeline_files)}\")\n",
    "        \n",
    "        if not model_files:\n",
    "            console.print(\"[red][FAIL] No model files found. Please run Phase 3 first.[/red]\")\n",
    "        if not pipeline_files:\n",
    "            console.print(\"[yellow][WARN] No pipeline files found. Pipeline may not load correctly.[/yellow]\")\n",
    "    else:\n",
    "        console.print(\"[red][FAIL] No model directories found. Please run Phase 3 first.[/red]\")\n",
    "else:\n",
    "    console.print(\"[red][FAIL] Models directory not found. Please run Phase 3 first.[/red]\")\n",
    "\n",
    "# Check processed data\n",
    "if processed_dir.exists():\n",
    "    processed_dirs = [d for d in processed_dir.iterdir() if d.is_dir()]\n",
    "    if processed_dirs:\n",
    "        console.print(f\"[green][OK] Processed data found: {len(processed_dirs)} versions[/green]\")\n",
    "    else:\n",
    "        console.print(\"[yellow][WARN] No processed data found. SHAP explanations may not work.[/yellow]\")\n",
    "else:\n",
    "    console.print(\"[yellow][WARN] Processed data directory not found.[/yellow]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Test Data\n",
    "\n",
    "We'll load sample customer data from the raw dataset to test the API.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[OK] Loaded raw data: 7043 customers\u001b[0m\n",
      "\u001b[32m[OK] Prepared 5 test customers\u001b[0m\n",
      "\n",
      "\u001b[1mSample Customer Data:\u001b[0m\n",
      "  customerID: 7590-VHVEG\n",
      "  gender: Female\n",
      "  SeniorCitizen: 0\n",
      "  Partner: Yes\n",
      "  Dependents: No\n",
      "  tenure: 1\n",
      "  PhoneService: No\n",
      "  MultipleLines: No phone service\n",
      "  InternetService: DSL\n",
      "  OnlineSecurity: No\n"
     ]
    }
   ],
   "source": [
    "# Load sample customer data for testing\n",
    "raw_data_path = PROJECT_ROOT / \"data\" / \"raw\" / \"telco_data_28_11_2025.csv\"\n",
    "\n",
    "if raw_data_path.exists():\n",
    "    df_raw = pd.read_csv(raw_data_path)\n",
    "    console.print(f\"[green][OK] Loaded raw data: {len(df_raw)} customers[/green]\")\n",
    "    \n",
    "    # Clean data (same as Phase 1)\n",
    "    df_raw.columns = [c.strip() for c in df_raw.columns]\n",
    "    df_raw[\"TotalCharges\"] = pd.to_numeric(df_raw[\"TotalCharges\"], errors=\"coerce\")\n",
    "    df_raw[\"SeniorCitizen\"] = df_raw[\"SeniorCitizen\"].astype(\"Int64\")\n",
    "    df_raw = df_raw.dropna(subset=[\"customerID\"])\n",
    "    df_raw[\"customerID\"] = df_raw[\"customerID\"].str.strip()\n",
    "    \n",
    "    # Select a few test customers\n",
    "    test_customers = df_raw.head(5).to_dict('records')\n",
    "    console.print(f\"[green][OK] Prepared {len(test_customers)} test customers[/green]\")\n",
    "    \n",
    "    # Display first customer\n",
    "    console.print(\"\\n[bold]Sample Customer Data:[/bold]\")\n",
    "    sample = test_customers[0]\n",
    "    for key, value in list(sample.items())[:10]:\n",
    "        console.print(f\"  {key}: {value}\")\n",
    "else:\n",
    "    console.print(\"[red][FAIL] Raw data not found. Creating sample data...[/red]\")\n",
    "    # Create sample data\n",
    "    test_customers = [\n",
    "        {\n",
    "            \"customerID\": \"1234-ABCD\",\n",
    "            \"gender\": \"Male\",\n",
    "            \"SeniorCitizen\": 0,\n",
    "            \"Partner\": \"Yes\",\n",
    "            \"Dependents\": \"No\",\n",
    "            \"tenure\": 12,\n",
    "            \"PhoneService\": \"Yes\",\n",
    "            \"MultipleLines\": \"No\",\n",
    "            \"InternetService\": \"DSL\",\n",
    "            \"OnlineSecurity\": \"No\",\n",
    "            \"OnlineBackup\": \"Yes\",\n",
    "            \"DeviceProtection\": \"No\",\n",
    "            \"TechSupport\": \"No\",\n",
    "            \"StreamingTV\": \"No\",\n",
    "            \"StreamingMovies\": \"No\",\n",
    "            \"Contract\": \"Month-to-month\",\n",
    "            \"PaperlessBilling\": \"Yes\",\n",
    "            \"PaymentMethod\": \"Electronic check\",\n",
    "            \"MonthlyCharges\": 70.5,\n",
    "            \"TotalCharges\": 845.0,\n",
    "        }\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Start API Service\n",
    "\n",
    "**Important**: The API service needs to be started separately in a terminal before running the tests below.\n",
    "\n",
    "Run this command in a terminal:\n",
    "```bash\n",
    "python scripts/run_phase4_api.py --port 8001\n",
    "# Or\n",
    "make phase4\n",
    "```\n",
    "\n",
    "The API will be available at `http://localhost:8001`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test API Endpoints\n",
    "\n",
    "Now we'll test all the API endpoints to verify functionality.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;36mTesting API Health...\u001b[0m\n",
      "\u001b[31m[FAIL] Cannot connect to API. Is it running?\u001b[0m\n",
      "\u001b[33m  Start it with: python scripts/run_phase4_api.py --port 8001\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# API base URL\n",
    "API_BASE_URL = \"http://localhost:8001\"\n",
    "\n",
    "def check_api_health() -> bool:\n",
    "    \"\"\"Check if API is running.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(f\"{API_BASE_URL}/health\", timeout=5)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            console.print(f\"[green][OK] API is healthy[/green]\")\n",
    "            console.print(f\"  Status: {data['status']}\")\n",
    "            console.print(f\"  Model loaded: {data['model_loaded']}\")\n",
    "            console.print(f\"  Pipeline loaded: {data['pipeline_loaded']}\")\n",
    "            return data['model_loaded'] and data['pipeline_loaded']\n",
    "        else:\n",
    "            console.print(f\"[red][FAIL] API returned status {response.status_code}[/red]\")\n",
    "            return False\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        console.print(\"[red][FAIL] Cannot connect to API. Is it running?[/red]\")\n",
    "        console.print(\"[yellow]  Start it with: python scripts/run_phase4_api.py --port 8001[/yellow]\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        console.print(f\"[red][FAIL] Error checking API: {e}[/red]\")\n",
    "        return False\n",
    "\n",
    "# Check health\n",
    "console.print(\"\\n[bold cyan]Testing API Health...[/bold cyan]\")\n",
    "api_ready = check_api_health()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m[WARN] Skipping metadata test - API not ready\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Get model metadata\n",
    "if api_ready:\n",
    "    console.print(\"\\n[bold cyan]Fetching Model Metadata...[/bold cyan]\")\n",
    "    try:\n",
    "        response = requests.get(f\"{API_BASE_URL}/metadata\", timeout=10)\n",
    "        if response.status_code == 200:\n",
    "            metadata = response.json()\n",
    "            \n",
    "            table = Table(title=\"Model Metadata\")\n",
    "            table.add_column(\"Property\", style=\"cyan\")\n",
    "            table.add_column(\"Value\", style=\"green\")\n",
    "            \n",
    "            table.add_row(\"Model Type\", metadata.get(\"model_type\", \"N/A\"))\n",
    "            table.add_row(\"Model Version\", metadata.get(\"model_version\", \"N/A\"))\n",
    "            table.add_row(\"Feature Count\", str(metadata.get(\"feature_count\", 0)))\n",
    "            table.add_row(\"Threshold\", str(metadata.get(\"threshold\", 0.5)))\n",
    "            \n",
    "            # Performance metrics\n",
    "            perf_metrics = metadata.get(\"performance_metrics\", {})\n",
    "            for metric, value in perf_metrics.items():\n",
    "                table.add_row(f\"Performance: {metric}\", f\"{value:.4f}\")\n",
    "            \n",
    "            console.print(table)\n",
    "            \n",
    "            # Show feature names (first 10)\n",
    "            feature_names = metadata.get(\"feature_names\", [])\n",
    "            if feature_names:\n",
    "                console.print(f\"\\n[dim]Features ({len(feature_names)} total): {', '.join(feature_names[:10])}...[/dim]\")\n",
    "        else:\n",
    "            console.print(f\"[red][FAIL] Failed to get metadata: {response.status_code}[/red]\")\n",
    "    except Exception as e:\n",
    "        console.print(f\"[red][FAIL] Error fetching metadata: {e}[/red]\")\n",
    "else:\n",
    "    console.print(\"[yellow][WARN] Skipping metadata test - API not ready[/yellow]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test Single Predictions\n",
    "\n",
    "Test the `/predict` endpoint with individual customers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m[WARN] Skipping prediction tests - API not ready\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if api_ready:\n",
    "    console.print(\"\\n[bold cyan]Testing Single Predictions...[/bold cyan]\")\n",
    "    \n",
    "    for i, customer in enumerate(test_customers[:3], 1):\n",
    "        console.print(f\"\\n[bold]Test Customer {i}: {customer.get('customerID', 'Unknown')}[/bold]\")\n",
    "        \n",
    "        try:\n",
    "            # Prepare request (ensure TotalCharges is handled)\n",
    "            request_data = customer.copy()\n",
    "            if pd.isna(request_data.get(\"TotalCharges\")):\n",
    "                request_data[\"TotalCharges\"] = None\n",
    "            else:\n",
    "                request_data[\"TotalCharges\"] = float(request_data[\"TotalCharges\"])\n",
    "            \n",
    "            # Make prediction\n",
    "            start_time = time.time()\n",
    "            response = requests.post(\n",
    "                f\"{API_BASE_URL}/predict\",\n",
    "                json=request_data,\n",
    "                timeout=30\n",
    "            )\n",
    "            elapsed_time = time.time() - start_time\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                result = response.json()\n",
    "                \n",
    "                console.print(f\"  [green][OK] Prediction successful ({elapsed_time:.3f}s)[/green]\")\n",
    "                console.print(f\"  Churn Probability: {result['churn_probability']:.4f}\")\n",
    "                console.print(f\"  Churn Prediction: {result['churn_prediction']}\")\n",
    "                console.print(f\"  Threshold: {result['threshold']}\")\n",
    "                \n",
    "                # Show top explanations\n",
    "                explanations = result.get('explanation', [])\n",
    "                if explanations:\n",
    "                    console.print(f\"  \\n  Top Features:\")\n",
    "                    for exp in explanations[:5]:\n",
    "                        shap_val = exp['shap_value']\n",
    "                        sign = \"+\" if shap_val >= 0 else \"\"\n",
    "                        console.print(f\"    {exp['feature']}: {sign}{shap_val:.4f}\")\n",
    "                else:\n",
    "                    console.print(f\"  [yellow]  [WARN] No explanations available[/yellow]\")\n",
    "            else:\n",
    "                console.print(f\"  [red][FAIL] Prediction failed: {response.status_code}[/red]\")\n",
    "                console.print(f\"  Error: {response.text}\")\n",
    "        except Exception as e:\n",
    "            console.print(f\"  [red][FAIL] Error: {e}[/red]\")\n",
    "else:\n",
    "    console.print(\"[yellow][WARN] Skipping prediction tests - API not ready[/yellow]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Test Batch Predictions\n",
    "\n",
    "Test the `/predict/batch` endpoint with multiple customers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m[WARN] Skipping batch prediction tests - API not ready\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if api_ready:\n",
    "    console.print(\"\\n[bold cyan]Testing Batch Predictions...[/bold cyan]\")\n",
    "    \n",
    "    # Prepare batch request\n",
    "    batch_customers = []\n",
    "    for customer in test_customers[:5]:\n",
    "        request_data = customer.copy()\n",
    "        if pd.isna(request_data.get(\"TotalCharges\")):\n",
    "            request_data[\"TotalCharges\"] = None\n",
    "        else:\n",
    "            request_data[\"TotalCharges\"] = float(request_data[\"TotalCharges\"])\n",
    "        batch_customers.append(request_data)\n",
    "    \n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        response = requests.post(\n",
    "            f\"{API_BASE_URL}/predict/batch\",\n",
    "            json={\"customers\": batch_customers},\n",
    "            timeout=60\n",
    "        )\n",
    "        elapsed_time = time.time() - start_time\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            \n",
    "            console.print(f\"[green][OK] Batch prediction successful ({elapsed_time:.3f}s)[/green]\")\n",
    "            console.print(f\"  Total customers: {result['total_customers']}\")\n",
    "            console.print(f\"  Predictions returned: {len(result['predictions'])}\")\n",
    "            \n",
    "            # Show summary\n",
    "            predictions = result['predictions']\n",
    "            churn_count = sum(1 for p in predictions if p['churn_prediction'])\n",
    "            avg_prob = np.mean([p['churn_probability'] for p in predictions])\n",
    "            \n",
    "            console.print(f\"\\n  Summary:\")\n",
    "            console.print(f\"    Churn predictions: {churn_count}/{len(predictions)}\")\n",
    "            console.print(f\"    Average probability: {avg_prob:.4f}\")\n",
    "            \n",
    "            # Show individual results\n",
    "            console.print(f\"\\n  Individual Results:\")\n",
    "            for pred in predictions:\n",
    "                console.print(f\"    {pred['customerID']}: {pred['churn_probability']:.4f} ({'Churn' if pred['churn_prediction'] else 'No Churn'})\")\n",
    "        else:\n",
    "            console.print(f\"[red][FAIL] Batch prediction failed: {response.status_code}[/red]\")\n",
    "            console.print(f\"  Error: {response.text}\")\n",
    "    except Exception as e:\n",
    "        console.print(f\"[red][FAIL] Error: {e}[/red]\")\n",
    "else:\n",
    "    console.print(\"[yellow][WARN] Skipping batch prediction tests - API not ready[/yellow]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Validation Tests\n",
    "\n",
    "Test input validation and error handling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m[WARN] Skipping validation tests - API not ready\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if api_ready:\n",
    "    console.print(\"\\n[bold cyan]Running Validation Tests...[/bold cyan]\")\n",
    "    \n",
    "    test_results = []\n",
    "    \n",
    "    # Test 1: Invalid customer data\n",
    "    console.print(\"\\n[bold]Test 1: Invalid customer data[/bold]\")\n",
    "    try:\n",
    "        invalid_data = {\"customerID\": \"test\", \"tenure\": -1}  # Invalid tenure\n",
    "        response = requests.post(f\"{API_BASE_URL}/predict\", json=invalid_data, timeout=10)\n",
    "        if response.status_code == 422:  # Validation error\n",
    "            console.print(\"  [green][OK] Validation error correctly returned[/green]\")\n",
    "            test_results.append((\"Validation\", True))\n",
    "        else:\n",
    "            console.print(f\"  [red][FAIL] Expected 422, got {response.status_code}[/red]\")\n",
    "            test_results.append((\"Validation\", False))\n",
    "    except Exception as e:\n",
    "        console.print(f\"  [red][FAIL] Error: {e}[/red]\")\n",
    "        test_results.append((\"Validation\", False))\n",
    "    \n",
    "    # Test 2: Missing required fields\n",
    "    console.print(\"\\n[bold]Test 2: Missing required fields[/bold]\")\n",
    "    try:\n",
    "        incomplete_data = {\"customerID\": \"test\"}\n",
    "        response = requests.post(f\"{API_BASE_URL}/predict\", json=incomplete_data, timeout=10)\n",
    "        if response.status_code == 422:\n",
    "            console.print(\"  [green][OK] Missing fields correctly rejected[/green]\")\n",
    "            test_results.append((\"Required Fields\", True))\n",
    "        else:\n",
    "            console.print(f\"  [red][FAIL] Expected 422, got {response.status_code}[/red]\")\n",
    "            test_results.append((\"Required Fields\", False))\n",
    "    except Exception as e:\n",
    "        console.print(f\"  [red][FAIL] Error: {e}[/red]\")\n",
    "        test_results.append((\"Required Fields\", False))\n",
    "    \n",
    "    # Test 3: Empty batch\n",
    "    console.print(\"\\n[bold]Test 3: Empty batch request[/bold]\")\n",
    "    try:\n",
    "        response = requests.post(f\"{API_BASE_URL}/predict/batch\", json={\"customers\": []}, timeout=10)\n",
    "        if response.status_code == 422:\n",
    "            console.print(\"  [green][OK] Empty batch correctly rejected[/green]\")\n",
    "            test_results.append((\"Empty Batch\", True))\n",
    "        else:\n",
    "            console.print(f\"  [red][FAIL] Expected 422, got {response.status_code}[/red]\")\n",
    "            test_results.append((\"Empty Batch\", False))\n",
    "    except Exception as e:\n",
    "        console.print(f\"  [red][FAIL] Error: {e}[/red]\")\n",
    "        test_results.append((\"Empty Batch\", False))\n",
    "    \n",
    "    # Summary\n",
    "    console.print(\"\\n[bold cyan]Validation Test Summary[/bold cyan]\")\n",
    "    passed = sum(1 for _, result in test_results if result)\n",
    "    total = len(test_results)\n",
    "    \n",
    "    table = Table(title=\"Test Results\")\n",
    "    table.add_column(\"Test\", style=\"cyan\")\n",
    "    table.add_column(\"Status\", style=\"green\")\n",
    "    \n",
    "    for test_name, result in test_results:\n",
    "        status = \"[green][OK] PASS[/green]\" if result else \"[red][FAIL] FAIL[/red]\"\n",
    "        table.add_row(test_name, status)\n",
    "    \n",
    "    console.print(table)\n",
    "    console.print(f\"\\n[bold]Total: {passed}/{total} tests passed[/bold]\")\n",
    "else:\n",
    "    console.print(\"[yellow][WARN] Skipping validation tests - API not ready[/yellow]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Performance Testing\n",
    "\n",
    "Measure API latency and throughput.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m[WARN] Skipping performance tests - API not ready\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if api_ready:\n",
    "    console.print(\"\\n[bold cyan]Performance Testing...[/bold cyan]\")\n",
    "    \n",
    "    # Test latency\n",
    "    num_requests = 10\n",
    "    latencies = []\n",
    "    \n",
    "    test_customer = test_customers[0].copy()\n",
    "    if pd.isna(test_customer.get(\"TotalCharges\")):\n",
    "        test_customer[\"TotalCharges\"] = None\n",
    "    else:\n",
    "        test_customer[\"TotalCharges\"] = float(test_customer[\"TotalCharges\"])\n",
    "    \n",
    "    console.print(f\"  Running {num_requests} requests...\")\n",
    "    \n",
    "    for i in range(num_requests):\n",
    "        try:\n",
    "            start_time = time.time()\n",
    "            response = requests.post(f\"{API_BASE_URL}/predict\", json=test_customer, timeout=30)\n",
    "            elapsed = time.time() - start_time\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                latencies.append(elapsed * 1000)  # Convert to ms\n",
    "            else:\n",
    "                console.print(f\"  [yellow][WARN] Request {i+1} failed: {response.status_code}[/yellow]\")\n",
    "        except Exception as e:\n",
    "            console.print(f\"  [red][FAIL] Request {i+1} error: {e}[/red]\")\n",
    "    \n",
    "    if latencies:\n",
    "        avg_latency = np.mean(latencies)\n",
    "        p50_latency = np.percentile(latencies, 50)\n",
    "        p95_latency = np.percentile(latencies, 95)\n",
    "        p99_latency = np.percentile(latencies, 99)\n",
    "        \n",
    "        console.print(f\"\\n  [green][OK] Performance Metrics:[/green]\")\n",
    "        console.print(f\"    Average: {avg_latency:.2f} ms\")\n",
    "        console.print(f\"    P50: {p50_latency:.2f} ms\")\n",
    "        console.print(f\"    P95: {p95_latency:.2f} ms\")\n",
    "        console.print(f\"    P99: {p99_latency:.2f} ms\")\n",
    "        \n",
    "        # FAANG-level requirements\n",
    "        if avg_latency < 100:\n",
    "            console.print(f\"    [green][OK] Average latency < 100ms (FAANG standard)[/green]\")\n",
    "        else:\n",
    "            console.print(f\"    [yellow][WARN] Average latency >= 100ms[/yellow]\")\n",
    "        \n",
    "        if p95_latency < 200:\n",
    "            console.print(f\"    [green][OK] P95 latency < 200ms (FAANG standard)[/green]\")\n",
    "        else:\n",
    "            console.print(f\"    [yellow][WARN] P95 latency >= 200ms[/yellow]\")\n",
    "        \n",
    "        # Create visualization\n",
    "        import matplotlib.pyplot as plt\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.hist(latencies, bins=20, edgecolor='black', alpha=0.7)\n",
    "        plt.axvline(avg_latency, color='red', linestyle='--', label=f'Mean: {avg_latency:.2f}ms')\n",
    "        plt.axvline(p95_latency, color='orange', linestyle='--', label=f'P95: {p95_latency:.2f}ms')\n",
    "        plt.xlabel('Latency (ms)')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.title('API Request Latency Distribution')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.show()\n",
    "    else:\n",
    "        console.print(\"  [red][FAIL] No successful requests for performance testing[/red]\")\n",
    "else:\n",
    "    console.print(\"[yellow][WARN] Skipping performance tests - API not ready[/yellow]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "\u001b[1;32mPhase 4 API Testing Complete!\u001b[0m\n",
      "================================================================================\n",
      "\n",
      "\u001b[1;36mNext Steps:\u001b[0m\n",
      "  1. Review API documentation at http://localhost:8001/docs\n",
      "  2. Integrate API with frontend applications\n",
      "  3. Set up monitoring and logging (Phase 5)\n",
      "  4. Deploy to production using Docker\n",
      "  5. Implement streaming pipeline (optional)\n",
      "\n",
      "\u001b[1;36mAPI Endpoints:\u001b[0m\n",
      "  - Health: http://localhost:8001/health\n",
      "  - Metadata: http://localhost:8001/metadata\n",
      "  - Predict: http://localhost:8001/predict\n",
      "  - Batch: http://localhost:8001/predict/batch\n",
      "  - Docs: http://localhost:8001/docs\n",
      "\n",
      "\u001b[1;36mKey Features Verified:\u001b[0m\n",
      "  [OK] Health check endpoint\n",
      "  [OK] Model metadata endpoint\n",
      "  [OK] Single prediction endpoint\n",
      "  [OK] Batch prediction endpoint\n",
      "  [OK] Input validation\n",
      "  [OK] SHAP explanations\n",
      "  [OK] Error handling\n"
     ]
    }
   ],
   "source": [
    "console.print(\"\\n\" + \"=\" * 80)\n",
    "console.print(\"[bold green]Phase 4 API Testing Complete![/bold green]\")\n",
    "console.print(\"=\" * 80)\n",
    "\n",
    "console.print(\"\\n[bold cyan]Next Steps:[/bold cyan]\")\n",
    "console.print(\"  1. Review API documentation at http://localhost:8001/docs\")\n",
    "console.print(\"  2. Integrate API with frontend applications\")\n",
    "console.print(\"  3. Set up monitoring and logging (Phase 5)\")\n",
    "console.print(\"  4. Deploy to production using Docker\")\n",
    "console.print(\"  5. Implement streaming pipeline (optional)\")\n",
    "\n",
    "console.print(\"\\n[bold cyan]API Endpoints:[/bold cyan]\")\n",
    "console.print(\"  - Health: http://localhost:8001/health\")\n",
    "console.print(\"  - Metadata: http://localhost:8001/metadata\")\n",
    "console.print(\"  - Predict: http://localhost:8001/predict\")\n",
    "console.print(\"  - Batch: http://localhost:8001/predict/batch\")\n",
    "console.print(\"  - Docs: http://localhost:8001/docs\")\n",
    "\n",
    "console.print(\"\\n[bold cyan]Key Features Verified:[/bold cyan]\")\n",
    "console.print(\"  [OK] Health check endpoint\")\n",
    "console.print(\"  [OK] Model metadata endpoint\")\n",
    "console.print(\"  [OK] Single prediction endpoint\")\n",
    "console.print(\"  [OK] Batch prediction endpoint\")\n",
    "console.print(\"  [OK] Input validation\")\n",
    "console.print(\"  [OK] SHAP explanations\")\n",
    "console.print(\"  [OK] Error handling\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
