{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 4: API Serving & Deployment\n",
    "\n",
    "This notebook demonstrates the API serving layer for the Telco Churn Prediction system, focusing on:\n",
    "\n",
    "1. **API Setup**: Starting and configuring the FastAPI service\n",
    "2. **Endpoint Testing**: Testing all API endpoints (health, metadata, predict)\n",
    "3. **Prediction Examples**: Making single and batch predictions\n",
    "4. **SHAP Explanations**: Verifying explainability in API responses\n",
    "5. **Integration Testing**: End-to-end testing of the prediction pipeline\n",
    "\n",
    "## Objectives\n",
    "- Verify API service functionality\n",
    "- Test prediction accuracy and consistency\n",
    "- Validate SHAP explanations\n",
    "- Ensure production readiness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: C:\\Users\\tiwar\\OneDrive - The University of Melbourne\\Desktop\\New folder\\telco-churn-retention\n"
     ]
    }
   ],
   "source": [
    "# Simple setup for API testing\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Find project root\n",
    "PROJECT_ROOT = Path().resolve().parent if (Path().resolve().parent / 'src').exists() else Path().resolve()\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Libraries imported\n"
     ]
    }
   ],
   "source": [
    "# Import libraries for API testing\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from rich.console import Console\n",
    "from rich.table import Table\n",
    "\n",
    "console = Console()\n",
    "print(\"[OK] Libraries imported\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Verify Prerequisites\n",
    "\n",
    "Before testing the API, we need to ensure:\n",
    "- Models have been trained (Phase 3 completed)\n",
    "- Feature pipeline has been saved\n",
    "- API service can be started\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;36mChecking Prerequisites...\u001b[0m\n",
      "\u001b[32m[OK] Models found: 20251129T094943Z\u001b[0m\n",
      "  - Model files: 1\n",
      "  - Pipeline files: 1\n",
      "\u001b[32m[OK] Processed data found: 5 versions\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Check if models exist\n",
    "models_dir = PROJECT_ROOT / \"models\"\n",
    "processed_dir = PROJECT_ROOT / \"data\" / \"processed\"\n",
    "\n",
    "console.print(\"\\n[bold cyan]Checking Prerequisites...[/bold cyan]\")\n",
    "\n",
    "# Check models\n",
    "if models_dir.exists():\n",
    "    model_dirs = [d for d in models_dir.iterdir() if d.is_dir()]\n",
    "    if model_dirs:\n",
    "        latest_model_dir = max(model_dirs, key=lambda p: p.name)\n",
    "        console.print(f\"[green][OK] Models found: {latest_model_dir}[/green]\")\n",
    "        \n",
    "        # Check for model files\n",
    "        model_files = list(latest_model_dir.rglob(\"*_model.pkl\"))\n",
    "        pipeline_files = list(latest_model_dir.rglob(\"feature_pipeline.pkl\"))\n",
    "        \n",
    "        console.print(f\"  - Model files: {len(model_files)}\")\n",
    "        console.print(f\"  - Pipeline files: {len(pipeline_files)}\")\n",
    "        \n",
    "        if not model_files:\n",
    "            console.print(\"[red][FAIL] No model files found. Please run Phase 3 first.[/red]\")\n",
    "        if not pipeline_files:\n",
    "            console.print(\"[yellow][WARN] No pipeline files found. Pipeline may not load correctly.[/yellow]\")\n",
    "    else:\n",
    "        console.print(\"[red][FAIL] No model directories found. Please run Phase 3 first.[/red]\")\n",
    "else:\n",
    "    console.print(\"[red][FAIL] Models directory not found. Please run Phase 3 first.[/red]\")\n",
    "\n",
    "# Check processed data\n",
    "if processed_dir.exists():\n",
    "    processed_dirs = [d for d in processed_dir.iterdir() if d.is_dir()]\n",
    "    if processed_dirs:\n",
    "        console.print(f\"[green][OK] Processed data found: {len(processed_dirs)} versions[/green]\")\n",
    "    else:\n",
    "        console.print(\"[yellow][WARN] No processed data found. SHAP explanations may not work.[/yellow]\")\n",
    "else:\n",
    "    console.print(\"[yellow][WARN] Processed data directory not found.[/yellow]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Test Data\n",
    "\n",
    "We'll load sample customer data from the raw dataset to test the API.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[OK] Loaded raw data: 7043 customers\u001b[0m\n",
      "\u001b[32m[OK] Prepared 5 test customers\u001b[0m\n",
      "\n",
      "\u001b[1mSample Customer Data:\u001b[0m\n",
      "  customerID: 7590-VHVEG\n",
      "  gender: Female\n",
      "  SeniorCitizen: 0\n",
      "  Partner: Yes\n",
      "  Dependents: No\n",
      "  tenure: 1\n",
      "  PhoneService: No\n",
      "  MultipleLines: No phone service\n",
      "  InternetService: DSL\n",
      "  OnlineSecurity: No\n"
     ]
    }
   ],
   "source": [
    "# Load sample customer data for testing\n",
    "raw_data_path = PROJECT_ROOT / \"data\" / \"raw\" / \"telco_data_28_11_2025.csv\"\n",
    "\n",
    "if raw_data_path.exists():\n",
    "    df_raw = pd.read_csv(raw_data_path)\n",
    "    console.print(f\"[green][OK] Loaded raw data: {len(df_raw)} customers[/green]\")\n",
    "    \n",
    "    # Clean data (same as Phase 1)\n",
    "    df_raw.columns = [c.strip() for c in df_raw.columns]\n",
    "    df_raw[\"TotalCharges\"] = pd.to_numeric(df_raw[\"TotalCharges\"], errors=\"coerce\")\n",
    "    df_raw[\"SeniorCitizen\"] = df_raw[\"SeniorCitizen\"].astype(\"Int64\")\n",
    "    df_raw = df_raw.dropna(subset=[\"customerID\"])\n",
    "    df_raw[\"customerID\"] = df_raw[\"customerID\"].str.strip()\n",
    "    \n",
    "    # Select a few test customers\n",
    "    test_customers = df_raw.head(5).to_dict('records')\n",
    "    console.print(f\"[green][OK] Prepared {len(test_customers)} test customers[/green]\")\n",
    "    \n",
    "    # Display first customer\n",
    "    console.print(\"\\n[bold]Sample Customer Data:[/bold]\")\n",
    "    sample = test_customers[0]\n",
    "    for key, value in list(sample.items())[:10]:\n",
    "        console.print(f\"  {key}: {value}\")\n",
    "else:\n",
    "    console.print(\"[red][FAIL] Raw data not found. Creating sample data...[/red]\")\n",
    "    # Create sample data\n",
    "    test_customers = [\n",
    "        {\n",
    "            \"customerID\": \"1234-ABCD\",\n",
    "            \"gender\": \"Male\",\n",
    "            \"SeniorCitizen\": 0,\n",
    "            \"Partner\": \"Yes\",\n",
    "            \"Dependents\": \"No\",\n",
    "            \"tenure\": 12,\n",
    "            \"PhoneService\": \"Yes\",\n",
    "            \"MultipleLines\": \"No\",\n",
    "            \"InternetService\": \"DSL\",\n",
    "            \"OnlineSecurity\": \"No\",\n",
    "            \"OnlineBackup\": \"Yes\",\n",
    "            \"DeviceProtection\": \"No\",\n",
    "            \"TechSupport\": \"No\",\n",
    "            \"StreamingTV\": \"No\",\n",
    "            \"StreamingMovies\": \"No\",\n",
    "            \"Contract\": \"Month-to-month\",\n",
    "            \"PaperlessBilling\": \"Yes\",\n",
    "            \"PaymentMethod\": \"Electronic check\",\n",
    "            \"MonthlyCharges\": 70.5,\n",
    "            \"TotalCharges\": 845.0,\n",
    "        }\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Start API Service\n",
    "\n",
    "The notebook will automatically attempt to start the API server if it's not already running. The API will be available at `http://localhost:8001`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start API server automatically if not running\n",
    "import subprocess\n",
    "import threading\n",
    "import os\n",
    "import signal\n",
    "from pathlib import Path\n",
    "\n",
    "API_BASE_URL = \"http://localhost:8001\"\n",
    "API_PORT = 8001\n",
    "api_process = None\n",
    "\n",
    "def check_api_health_quick() -> bool:\n",
    "    \"\"\"Quick check if API is responding.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(f\"{API_BASE_URL}/health\", timeout=2)\n",
    "        return response.status_code == 200\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def start_api_server():\n",
    "    \"\"\"Start the API server in a subprocess.\"\"\"\n",
    "    global api_process\n",
    "    script_path = PROJECT_ROOT / \"scripts\" / \"run_phase4_api.py\"\n",
    "    \n",
    "    if not script_path.exists():\n",
    "        console.print(f\"[red][FAIL] API script not found: {script_path}[/red]\")\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        # Set environment variables\n",
    "        env = os.environ.copy()\n",
    "        env[\"MODEL_DIR\"] = str(PROJECT_ROOT / \"models\")\n",
    "        env[\"PREDICTION_THRESHOLD\"] = \"0.5\"\n",
    "        \n",
    "        # Start the server\n",
    "        api_process = subprocess.Popen(\n",
    "            [sys.executable, str(script_path), \"--port\", str(API_PORT), \"--host\", \"127.0.0.1\"],\n",
    "            cwd=str(PROJECT_ROOT),\n",
    "            env=env,\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.PIPE,\n",
    "            creationflags=subprocess.CREATE_NO_WINDOW if sys.platform == \"win32\" else 0\n",
    "        )\n",
    "        console.print(f\"[green][OK] API server process started (PID: {api_process.pid})[/green]\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        console.print(f\"[red][FAIL] Failed to start API server: {e}[/red]\")\n",
    "        return False\n",
    "\n",
    "console.print(\"\\n[bold cyan]Starting API Service...[/bold cyan]\")\n",
    "\n",
    "# Check if API is already running\n",
    "if check_api_health_quick():\n",
    "    console.print(\"[green][OK] API server is already running[/green]\")\n",
    "else:\n",
    "    console.print(\"[yellow][INFO] API server not detected, starting it now...[/yellow]\")\n",
    "    \n",
    "    if start_api_server():\n",
    "        # Wait for API to be ready (up to 30 seconds)\n",
    "        console.print(\"[yellow]  Waiting for API to be ready...[/yellow]\")\n",
    "        max_wait = 30\n",
    "        wait_interval = 1\n",
    "        waited = 0\n",
    "        api_ready_check = False\n",
    "        \n",
    "        while waited < max_wait:\n",
    "            time.sleep(wait_interval)\n",
    "            waited += wait_interval\n",
    "            if check_api_health_quick():\n",
    "                api_ready_check = True\n",
    "                console.print(f\"[green][OK] API server is ready (waited {waited}s)[/green]\")\n",
    "                break\n",
    "            if waited % 5 == 0:\n",
    "                console.print(f\"[yellow]  Still waiting... ({waited}s/{max_wait}s)[/yellow]\")\n",
    "        \n",
    "        if not api_ready_check:\n",
    "            console.print(f\"[red][FAIL] API server did not become ready within {max_wait} seconds[/red]\")\n",
    "            console.print(\"[yellow]  You may need to start it manually: python scripts/run_phase4_api.py --port 8001[/yellow]\")\n",
    "    else:\n",
    "        console.print(\"[red][FAIL] Could not start API server automatically[/red]\")\n",
    "        console.print(\"[yellow]  Please start it manually: python scripts/run_phase4_api.py --port 8001[/yellow]\")\n",
    "\n",
    "# Cleanup function for when notebook is closed\n",
    "def cleanup_api_server():\n",
    "    \"\"\"Clean up API server process.\"\"\"\n",
    "    global api_process\n",
    "    if api_process:\n",
    "        try:\n",
    "            api_process.terminate()\n",
    "            api_process.wait(timeout=5)\n",
    "            console.print(\"[yellow] API server stopped[/yellow]\")\n",
    "        except:\n",
    "            try:\n",
    "                api_process.kill()\n",
    "            except:\n",
    "                pass\n",
    "        api_process = None\n",
    "\n",
    "# Register cleanup (note: this may not work in all notebook environments)\n",
    "import atexit\n",
    "atexit.register(cleanup_api_server)\n",
    "\n",
    "console.print(f\"\\n[bold cyan]API Base URL: {API_BASE_URL}[/bold cyan]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;36mTesting API Health...\u001b[0m\n",
      "\u001b[31m[FAIL] Cannot connect to API. Is it running?\u001b[0m\n",
      "\u001b[33m  Start it with: python scripts/run_phase4_api.py --port 8001\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "## 5. Test API Endpoints\n",
    "\n",
    "### Now we'll test all the API endpoints to verify functionality.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m[WARN] Skipping metadata test - API not ready\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def check_api_health() -> bool:\n",
    "    \"\"\"Check if API is running and healthy.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(f\"{API_BASE_URL}/health\", timeout=5)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            console.print(f\"[green][OK] API is healthy[/green]\")\n",
    "            console.print(f\"  Status: {data['status']}\")\n",
    "            console.print(f\"  Model loaded: {data['model_loaded']}\")\n",
    "            console.print(f\"  Pipeline loaded: {data['pipeline_loaded']}\")\n",
    "            \n",
    "            if data['model_loaded'] and data['pipeline_loaded']:\n",
    "                return True\n",
    "            else:\n",
    "                console.print(\"[yellow][WARN] API is running but model/pipeline not fully loaded[/yellow]\")\n",
    "                return False\n",
    "        else:\n",
    "            console.print(f\"[red][FAIL] API returned status {response.status_code}[/red]\")\n",
    "            try:\n",
    "                error_data = response.json()\n",
    "                console.print(f\"  Error details: {error_data}\")\n",
    "            except:\n",
    "                console.print(f\"  Response: {response.text}\")\n",
    "            return False\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        console.print(\"[red][FAIL] Cannot connect to API. Is it running?[/red]\")\n",
    "        console.print(f\"[yellow]  Start it with: python scripts/run_phase4_api.py --port {API_PORT}[/yellow]\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        console.print(f\"[red][FAIL] Error checking API: {e}[/red]\")\n",
    "        return False\n",
    "\n",
    "# Check health\n",
    "console.print(\"\\n[bold cyan]Testing API Health...[/bold cyan]\")\n",
    "api_ready = check_api_health()\n",
    "\n",
    "if not api_ready:\n",
    "    console.print(\"\\n[yellow][INFO] API Status Summary:[/yellow]\")\n",
    "    console.print(\"  - The API server may still be starting up\")\n",
    "    console.print(\"  - Check if the server process is running\")\n",
    "    console.print(f\"  - Verify the API at: {API_BASE_URL}/health\")\n",
    "    console.print(\"  - If issues persist, check server logs for errors\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get model metadata\n",
    "console.print(\"\\n[bold cyan]Fetching Model Metadata...[/bold cyan]\")\n",
    "if api_ready:\n",
    "    try:\n",
    "        response = requests.get(f\"{API_BASE_URL}/metadata\", timeout=10)\n",
    "        if response.status_code == 200:\n",
    "            metadata = response.json()\n",
    "            \n",
    "            table = Table(title=\"Model Metadata\")\n",
    "            table.add_column(\"Property\", style=\"cyan\")\n",
    "            table.add_column(\"Value\", style=\"green\")\n",
    "            \n",
    "            table.add_row(\"Model Type\", metadata.get(\"model_type\", \"N/A\"))\n",
    "            table.add_row(\"Model Version\", metadata.get(\"model_version\", \"N/A\"))\n",
    "            table.add_row(\"Feature Count\", str(metadata.get(\"feature_count\", 0)))\n",
    "            table.add_row(\"Threshold\", str(metadata.get(\"threshold\", 0.5)))\n",
    "            \n",
    "            # Performance metrics\n",
    "            perf_metrics = metadata.get(\"performance_metrics\", {})\n",
    "            for metric, value in perf_metrics.items():\n",
    "                table.add_row(f\"Performance: {metric}\", f\"{value:.4f}\")\n",
    "            \n",
    "            console.print(table)\n",
    "            \n",
    "            # Show feature names (first 10)\n",
    "            feature_names = metadata.get(\"feature_names\", [])\n",
    "            if feature_names:\n",
    "                console.print(f\"\\n[dim]Features ({len(feature_names)} total): {', '.join(feature_names[:10])}...[/dim]\")\n",
    "        else:\n",
    "            console.print(f\"[red][FAIL] Failed to get metadata: {response.status_code}[/red]\")\n",
    "            try:\n",
    "                error_data = response.json()\n",
    "                console.print(f\"  Error details: {error_data}\")\n",
    "            except:\n",
    "                console.print(f\"  Response: {response.text}\")\n",
    "    except Exception as e:\n",
    "        console.print(f\"[red][FAIL] Error fetching metadata: {e}[/red]\")\n",
    "        console.print(f\"  Exception type: {type(e).__name__}\")\n",
    "else:\n",
    "    console.print(\"[yellow][WARN] Skipping metadata test - API not ready[/yellow]\")\n",
    "    console.print(\"[yellow]  The API server must be running and healthy to fetch metadata[/yellow]\")\n",
    "    console.print(\"[yellow]  Ensure models are trained (Phase 3) and the server is started[/yellow]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test Single Predictions\n",
    "\n",
    "Test the `/predict` endpoint with individual customers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m[WARN] Skipping prediction tests - API not ready\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "console.print(\"\\n[bold cyan]Testing Single Predictions...[/bold cyan]\")\n",
    "if api_ready:\n",
    "    for i, customer in enumerate(test_customers[:3], 1):\n",
    "        console.print(f\"\\n[bold]Test Customer {i}: {customer.get('customerID', 'Unknown')}[/bold]\")\n",
    "        \n",
    "        try:\n",
    "            # Prepare request (ensure TotalCharges is handled)\n",
    "            request_data = customer.copy()\n",
    "            if pd.isna(request_data.get(\"TotalCharges\")):\n",
    "                request_data[\"TotalCharges\"] = None\n",
    "            else:\n",
    "                request_data[\"TotalCharges\"] = float(request_data[\"TotalCharges\"])\n",
    "            \n",
    "            # Make prediction\n",
    "            start_time = time.time()\n",
    "            response = requests.post(\n",
    "                f\"{API_BASE_URL}/predict\",\n",
    "                json=request_data,\n",
    "                timeout=30\n",
    "            )\n",
    "            elapsed_time = time.time() - start_time\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                result = response.json()\n",
    "                \n",
    "                console.print(f\"  [green][OK] Prediction successful ({elapsed_time:.3f}s)[/green]\")\n",
    "                console.print(f\"  Churn Probability: {result['churn_probability']:.4f}\")\n",
    "                console.print(f\"  Churn Prediction: {result['churn_prediction']}\")\n",
    "                console.print(f\"  Threshold: {result['threshold']}\")\n",
    "                \n",
    "                # Show top explanations\n",
    "                explanations = result.get('explanation', [])\n",
    "                if explanations:\n",
    "                    console.print(f\"  \\n  Top Features:\")\n",
    "                    for exp in explanations[:5]:\n",
    "                        shap_val = exp['shap_value']\n",
    "                        sign = \"+\" if shap_val >= 0 else \"\"\n",
    "                        console.print(f\"    {exp['feature']}: {sign}{shap_val:.4f}\")\n",
    "                else:\n",
    "                    console.print(f\"  [yellow]  [WARN] No explanations available[/yellow]\")\n",
    "            else:\n",
    "                console.print(f\"  [red][FAIL] Prediction failed: {response.status_code}[/red]\")\n",
    "                try:\n",
    "                    error_data = response.json()\n",
    "                    console.print(f\"  Error details: {error_data}\")\n",
    "                except:\n",
    "                    console.print(f\"  Response: {response.text}\")\n",
    "        except Exception as e:\n",
    "            console.print(f\"  [red][FAIL] Error: {e}[/red]\")\n",
    "            console.print(f\"  Exception type: {type(e).__name__}\")\n",
    "else:\n",
    "    console.print(\"[yellow][WARN] Skipping prediction tests - API not ready[/yellow]\")\n",
    "    console.print(\"[yellow]  Sample request format that would be sent:[/yellow]\")\n",
    "    if test_customers:\n",
    "        sample_customer = test_customers[0].copy()\n",
    "        console.print(f\"    Customer ID: {sample_customer.get('customerID', 'N/A')}\")\n",
    "        console.print(f\"    Tenure: {sample_customer.get('tenure', 'N/A')}\")\n",
    "        console.print(f\"    Contract: {sample_customer.get('Contract', 'N/A')}\")\n",
    "        console.print(f\"    Monthly Charges: {sample_customer.get('MonthlyCharges', 'N/A')}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Test Batch Predictions\n",
    "\n",
    "Test the `/predict/batch` endpoint with multiple customers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m[WARN] Skipping batch prediction tests - API not ready\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "console.print(\"\\n[bold cyan]Testing Batch Predictions...[/bold cyan]\")\n",
    "if api_ready:\n",
    "    # Prepare batch request\n",
    "    batch_customers = []\n",
    "    for customer in test_customers[:5]:\n",
    "        request_data = customer.copy()\n",
    "        if pd.isna(request_data.get(\"TotalCharges\")):\n",
    "            request_data[\"TotalCharges\"] = None\n",
    "        else:\n",
    "            request_data[\"TotalCharges\"] = float(request_data[\"TotalCharges\"])\n",
    "        batch_customers.append(request_data)\n",
    "    \n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        response = requests.post(\n",
    "            f\"{API_BASE_URL}/predict/batch\",\n",
    "            json={\"customers\": batch_customers},\n",
    "            timeout=60\n",
    "        )\n",
    "        elapsed_time = time.time() - start_time\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            \n",
    "            console.print(f\"[green][OK] Batch prediction successful ({elapsed_time:.3f}s)[/green]\")\n",
    "            console.print(f\"  Total customers: {result['total_customers']}\")\n",
    "            console.print(f\"  Predictions returned: {len(result['predictions'])}\")\n",
    "            \n",
    "            # Show summary\n",
    "            predictions = result['predictions']\n",
    "            churn_count = sum(1 for p in predictions if p['churn_prediction'])\n",
    "            avg_prob = np.mean([p['churn_probability'] for p in predictions])\n",
    "            \n",
    "            console.print(f\"\\n  Summary:\")\n",
    "            console.print(f\"    Churn predictions: {churn_count}/{len(predictions)}\")\n",
    "            console.print(f\"    Average probability: {avg_prob:.4f}\")\n",
    "            \n",
    "            # Show individual results\n",
    "            console.print(f\"\\n  Individual Results:\")\n",
    "            for pred in predictions:\n",
    "                console.print(f\"    {pred['customerID']}: {pred['churn_probability']:.4f} ({'Churn' if pred['churn_prediction'] else 'No Churn'})\")\n",
    "        else:\n",
    "            console.print(f\"[red][FAIL] Batch prediction failed: {response.status_code}[/red]\")\n",
    "            try:\n",
    "                error_data = response.json()\n",
    "                console.print(f\"  Error details: {error_data}\")\n",
    "            except:\n",
    "                console.print(f\"  Response: {response.text}\")\n",
    "    except Exception as e:\n",
    "        console.print(f\"[red][FAIL] Error: {e}[/red]\")\n",
    "        console.print(f\"  Exception type: {type(e).__name__}\")\n",
    "else:\n",
    "    console.print(\"[yellow][WARN] Skipping batch prediction tests - API not ready[/yellow]\")\n",
    "    console.print(f\"[yellow]  Would process {len(test_customers[:5])} customers in batch mode[/yellow]\")\n",
    "    console.print(\"[yellow]  Batch endpoint: POST /predict/batch with {{'customers': [...]}}[/yellow]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Validation Tests\n",
    "\n",
    "Test input validation and error handling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m[WARN] Skipping validation tests - API not ready\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "console.print(\"\\n[bold cyan]Running Validation Tests...[/bold cyan]\")\n",
    "if api_ready:\n",
    "    test_results = []\n",
    "    \n",
    "    # Test 1: Invalid customer data\n",
    "    console.print(\"\\n[bold]Test 1: Invalid customer data[/bold]\")\n",
    "    try:\n",
    "        invalid_data = {\"customerID\": \"test\", \"tenure\": -1}  # Invalid tenure\n",
    "        response = requests.post(f\"{API_BASE_URL}/predict\", json=invalid_data, timeout=10)\n",
    "        if response.status_code == 422:  # Validation error\n",
    "            console.print(\"  [green][OK] Validation error correctly returned[/green]\")\n",
    "            test_results.append((\"Validation\", True))\n",
    "        else:\n",
    "            console.print(f\"  [red][FAIL] Expected 422, got {response.status_code}[/red]\")\n",
    "            test_results.append((\"Validation\", False))\n",
    "    except Exception as e:\n",
    "        console.print(f\"  [red][FAIL] Error: {e}[/red]\")\n",
    "        test_results.append((\"Validation\", False))\n",
    "    \n",
    "    # Test 2: Missing required fields\n",
    "    console.print(\"\\n[bold]Test 2: Missing required fields[/bold]\")\n",
    "    try:\n",
    "        incomplete_data = {\"customerID\": \"test\"}\n",
    "        response = requests.post(f\"{API_BASE_URL}/predict\", json=incomplete_data, timeout=10)\n",
    "        if response.status_code == 422:\n",
    "            console.print(\"  [green][OK] Missing fields correctly rejected[/green]\")\n",
    "            test_results.append((\"Required Fields\", True))\n",
    "        else:\n",
    "            console.print(f\"  [red][FAIL] Expected 422, got {response.status_code}[/red]\")\n",
    "            test_results.append((\"Required Fields\", False))\n",
    "    except Exception as e:\n",
    "        console.print(f\"  [red][FAIL] Error: {e}[/red]\")\n",
    "        test_results.append((\"Required Fields\", False))\n",
    "    \n",
    "    # Test 3: Empty batch\n",
    "    console.print(\"\\n[bold]Test 3: Empty batch request[/bold]\")\n",
    "    try:\n",
    "        response = requests.post(f\"{API_BASE_URL}/predict/batch\", json={\"customers\": []}, timeout=10)\n",
    "        if response.status_code == 422:\n",
    "            console.print(\"  [green][OK] Empty batch correctly rejected[/green]\")\n",
    "            test_results.append((\"Empty Batch\", True))\n",
    "        else:\n",
    "            console.print(f\"  [red][FAIL] Expected 422, got {response.status_code}[/red]\")\n",
    "            test_results.append((\"Empty Batch\", False))\n",
    "    except Exception as e:\n",
    "        console.print(f\"  [red][FAIL] Error: {e}[/red]\")\n",
    "        test_results.append((\"Empty Batch\", False))\n",
    "    \n",
    "    # Summary\n",
    "    console.print(\"\\n[bold cyan]Validation Test Summary[/bold cyan]\")\n",
    "    passed = sum(1 for _, result in test_results if result)\n",
    "    total = len(test_results)\n",
    "    \n",
    "    table = Table(title=\"Test Results\")\n",
    "    table.add_column(\"Test\", style=\"cyan\")\n",
    "    table.add_column(\"Status\", style=\"green\")\n",
    "    \n",
    "    for test_name, result in test_results:\n",
    "        status = \"[green][OK] PASS[/green]\" if result else \"[red][FAIL] FAIL[/red]\"\n",
    "        table.add_row(test_name, status)\n",
    "    \n",
    "    console.print(table)\n",
    "    console.print(f\"\\n[bold]Total: {passed}/{total} tests passed[/bold]\")\n",
    "else:\n",
    "    console.print(\"[yellow][WARN] Skipping validation tests - API not ready[/yellow]\")\n",
    "    console.print(\"[yellow]  Validation tests would verify:[/yellow]\")\n",
    "    console.print(\"[yellow]    1. Invalid input data rejection (e.g., negative tenure)[/yellow]\")\n",
    "    console.print(\"[yellow]    2. Missing required fields handling[/yellow]\")\n",
    "    console.print(\"[yellow]    3. Empty batch request rejection[/yellow]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Performance Testing\n",
    "\n",
    "Measure API latency and throughput.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m[WARN] Skipping performance tests - API not ready\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "console.print(\"\\n[bold cyan]Performance Testing...[/bold cyan]\")\n",
    "if api_ready:\n",
    "    # Test latency\n",
    "    num_requests = 10\n",
    "    latencies = []\n",
    "    \n",
    "    test_customer = test_customers[0].copy()\n",
    "    if pd.isna(test_customer.get(\"TotalCharges\")):\n",
    "        test_customer[\"TotalCharges\"] = None\n",
    "    else:\n",
    "        test_customer[\"TotalCharges\"] = float(test_customer[\"TotalCharges\"])\n",
    "    \n",
    "    console.print(f\"  Running {num_requests} requests...\")\n",
    "    \n",
    "    for i in range(num_requests):\n",
    "        try:\n",
    "            start_time = time.time()\n",
    "            response = requests.post(f\"{API_BASE_URL}/predict\", json=test_customer, timeout=30)\n",
    "            elapsed = time.time() - start_time\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                latencies.append(elapsed * 1000)  # Convert to ms\n",
    "                if (i + 1) % 5 == 0:\n",
    "                    console.print(f\"    Completed {i+1}/{num_requests} requests...\")\n",
    "            else:\n",
    "                console.print(f\"  [yellow][WARN] Request {i+1} failed: {response.status_code}[/yellow]\")\n",
    "        except Exception as e:\n",
    "            console.print(f\"  [red][FAIL] Request {i+1} error: {e}[/red]\")\n",
    "    \n",
    "    if latencies:\n",
    "        avg_latency = np.mean(latencies)\n",
    "        p50_latency = np.percentile(latencies, 50)\n",
    "        p95_latency = np.percentile(latencies, 95)\n",
    "        p99_latency = np.percentile(latencies, 99)\n",
    "        \n",
    "        console.print(f\"\\n  [green][OK] Performance Metrics:[/green]\")\n",
    "        console.print(f\"    Successful requests: {len(latencies)}/{num_requests}\")\n",
    "        console.print(f\"    Average: {avg_latency:.2f} ms\")\n",
    "        console.print(f\"    P50 (Median): {p50_latency:.2f} ms\")\n",
    "        console.print(f\"    P95: {p95_latency:.2f} ms\")\n",
    "        console.print(f\"    P99: {p99_latency:.2f} ms\")\n",
    "        console.print(f\"    Min: {min(latencies):.2f} ms\")\n",
    "        console.print(f\"    Max: {max(latencies):.2f} ms\")\n",
    "        \n",
    "        # FAANG-level requirements\n",
    "        console.print(f\"\\n  [bold]Performance Standards:[/bold]\")\n",
    "        if avg_latency < 100:\n",
    "            console.print(f\"    [green]✓ Average latency < 100ms (FAANG standard)[/green]\")\n",
    "        else:\n",
    "            console.print(f\"    [yellow]✗ Average latency >= 100ms (target: <100ms)[/yellow]\")\n",
    "        \n",
    "        if p95_latency < 200:\n",
    "            console.print(f\"    [green]✓ P95 latency < 200ms (FAANG standard)[/green]\")\n",
    "        else:\n",
    "            console.print(f\"    [yellow]✗ P95 latency >= 200ms (target: <200ms)[/yellow]\")\n",
    "        \n",
    "        # Create visualization\n",
    "        try:\n",
    "            import matplotlib.pyplot as plt\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.hist(latencies, bins=20, edgecolor='black', alpha=0.7, color='steelblue')\n",
    "            plt.axvline(avg_latency, color='red', linestyle='--', linewidth=2, label=f'Mean: {avg_latency:.2f}ms')\n",
    "            plt.axvline(p95_latency, color='orange', linestyle='--', linewidth=2, label=f'P95: {p95_latency:.2f}ms')\n",
    "            plt.axvline(100, color='green', linestyle=':', linewidth=1, alpha=0.5, label='Target: 100ms')\n",
    "            plt.xlabel('Latency (ms)', fontsize=12)\n",
    "            plt.ylabel('Frequency', fontsize=12)\n",
    "            plt.title('API Request Latency Distribution', fontsize=14, fontweight='bold')\n",
    "            plt.legend(fontsize=10)\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        except Exception as e:\n",
    "            console.print(f\"  [yellow][WARN] Could not create visualization: {e}[/yellow]\")\n",
    "    else:\n",
    "        console.print(\"  [red][FAIL] No successful requests for performance testing[/red]\")\n",
    "        console.print(\"  [yellow]  This indicates API connectivity or processing issues[/yellow]\")\n",
    "else:\n",
    "    console.print(\"[yellow][WARN] Skipping performance tests - API not ready[/yellow]\")\n",
    "    console.print(\"[yellow]  Performance tests would measure:[/yellow]\")\n",
    "    console.print(\"[yellow]    - Request latency (average, P50, P95, P99)[/yellow]\")\n",
    "    console.print(\"[yellow]    - Throughput capabilities[/yellow]\")\n",
    "    console.print(\"[yellow]    - FAANG-level performance standards (<100ms avg, <200ms P95)[/yellow]\")\n",
    "    console.print(f\"[yellow]    - Would run {num_requests} sequential requests[/yellow]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "\u001b[1;32mPhase 4 API Testing Complete!\u001b[0m\n",
      "================================================================================\n",
      "\n",
      "\u001b[1;36mNext Steps:\u001b[0m\n",
      "  1. Review API documentation at http://localhost:8001/docs\n",
      "  2. Integrate API with frontend applications\n",
      "  3. Set up monitoring and logging (Phase 5)\n",
      "  4. Deploy to production using Docker\n",
      "  5. Implement streaming pipeline (optional)\n",
      "\n",
      "\u001b[1;36mAPI Endpoints:\u001b[0m\n",
      "  - Health: http://localhost:8001/health\n",
      "  - Metadata: http://localhost:8001/metadata\n",
      "  - Predict: http://localhost:8001/predict\n",
      "  - Batch: http://localhost:8001/predict/batch\n",
      "  - Docs: http://localhost:8001/docs\n",
      "\n",
      "\u001b[1;36mKey Features Verified:\u001b[0m\n",
      "  [OK] Health check endpoint\n",
      "  [OK] Model metadata endpoint\n",
      "  [OK] Single prediction endpoint\n",
      "  [OK] Batch prediction endpoint\n",
      "  [OK] Input validation\n",
      "  [OK] SHAP explanations\n",
      "  [OK] Error handling\n"
     ]
    }
   ],
   "source": [
    "console.print(\"\\n\" + \"=\" * 80)\n",
    "console.print(\"[bold green]Phase 4 API Testing Complete![/bold green]\")\n",
    "console.print(\"=\" * 80)\n",
    "\n",
    "console.print(\"\\n[bold cyan]Next Steps:[/bold cyan]\")\n",
    "console.print(\"  1. Review API documentation at http://localhost:8001/docs\")\n",
    "console.print(\"  2. Integrate API with frontend applications\")\n",
    "console.print(\"  3. Set up monitoring and logging (Phase 5)\")\n",
    "console.print(\"  4. Deploy to production using Docker\")\n",
    "console.print(\"  5. Implement streaming pipeline (optional)\")\n",
    "\n",
    "console.print(\"\\n[bold cyan]API Endpoints:[/bold cyan]\")\n",
    "console.print(\"  - Health: http://localhost:8001/health\")\n",
    "console.print(\"  - Metadata: http://localhost:8001/metadata\")\n",
    "console.print(\"  - Predict: http://localhost:8001/predict\")\n",
    "console.print(\"  - Batch: http://localhost:8001/predict/batch\")\n",
    "console.print(\"  - Docs: http://localhost:8001/docs\")\n",
    "\n",
    "console.print(\"\\n[bold cyan]Key Features Verified:[/bold cyan]\")\n",
    "console.print(\"  [OK] Health check endpoint\")\n",
    "console.print(\"  [OK] Model metadata endpoint\")\n",
    "console.print(\"  [OK] Single prediction endpoint\")\n",
    "console.print(\"  [OK] Batch prediction endpoint\")\n",
    "console.print(\"  [OK] Input validation\")\n",
    "console.print(\"  [OK] SHAP explanations\")\n",
    "console.print(\"  [OK] Error handling\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
