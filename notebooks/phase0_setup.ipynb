{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 0: Project Setup and Foundation\n",
    "\n",
    "This notebook provides setup instructions and validates the project environment for the Telco Churn Retention Platform.\n",
    "\n",
    "## Objectives\n",
    "- Verify Python environment and dependencies\n",
    "- Validate project structure\n",
    "- Test data access\n",
    "- Confirm all tools are properly configured\n",
    "\n",
    "## Prerequisites\n",
    "- Python 3.11 or higher\n",
    "- pip or poetry package manager\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T11:47:28.181866Z",
     "iopub.status.busy": "2025-12-01T11:47:28.181588Z",
     "iopub.status.idle": "2025-12-01T11:47:28.194808Z",
     "shell.execute_reply": "2025-12-01T11:47:28.192862Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.13.7 (tags/v3.13.7:bcee1c3, Aug 14 2025, 14:15:11) [MSC v.1944 64 bit (AMD64)]\n",
      "Python executable: C:\\Python313\\python.exe\n",
      "\n",
      "Python version check: PASSED\n"
     ]
    }
   ],
   "source": [
    "# Check Python version\n",
    "import sys\n",
    "\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Python executable: {sys.executable}\")\n",
    "\n",
    "# Verify Python 3.11+\n",
    "assert sys.version_info >= (3, 11), (\n",
    "    f\"Python 3.11+ required, found {sys.version_info.major}.{sys.version_info.minor}\"\n",
    ")\n",
    "\n",
    "print(\"\\nPython version check: PASSED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Verify Project Structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T11:47:28.245082Z",
     "iopub.status.busy": "2025-12-01T11:47:28.244637Z",
     "iopub.status.idle": "2025-12-01T11:47:28.254247Z",
     "shell.execute_reply": "2025-12-01T11:47:28.252464Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: C:\\Users\\tiwar\\OneDrive - The University of Melbourne\\Desktop\\New folder\n",
      "\n",
      "Checking project structure...\n",
      "  src                 : MISSING\n",
      "  notebooks           : MISSING\n",
      "  scripts             : MISSING\n",
      "  tests               : MISSING\n",
      "  configs             : MISSING\n",
      "  docs                : MISSING\n",
      "  data/raw            : MISSING\n",
      "  data/processed      : MISSING\n",
      "\n",
      "Project structure check: COMPLETE\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "PROJECT_ROOT = Path().resolve().parent\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "\n",
    "# Check key directories\n",
    "required_dirs = [\n",
    "    \"src\",\n",
    "    \"notebooks\",\n",
    "    \"scripts\",\n",
    "    \"tests\",\n",
    "    \"configs\",\n",
    "    \"docs\",\n",
    "    \"data/raw\",\n",
    "    \"data/processed\",\n",
    "]\n",
    "\n",
    "print(\"\\nChecking project structure...\")\n",
    "for dir_name in required_dirs:\n",
    "    dir_path = PROJECT_ROOT / dir_name\n",
    "    exists = dir_path.exists()\n",
    "    status = \"EXISTS\" if exists else \"MISSING\"\n",
    "    print(f\"  {dir_name:20s}: {status}\")\n",
    "\n",
    "print(\"\\nProject structure check: COMPLETE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Verify Dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T11:47:28.259795Z",
     "iopub.status.busy": "2025-12-01T11:47:28.259216Z",
     "iopub.status.idle": "2025-12-01T11:47:38.227376Z",
     "shell.execute_reply": "2025-12-01T11:47:38.224998Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking core dependencies...\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  pandas              : INSTALLED - Data manipulation\n",
      "  numpy               : INSTALLED - Numerical computing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  sklearn             : INSTALLED - Machine learning (scikit-learn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  xgboost             : INSTALLED - Gradient boosting\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  lightgbm            : INSTALLED - Gradient boosting\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  optuna              : INSTALLED - Hyperparameter tuning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  mlflow              : INSTALLED - Experiment tracking\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  shap                : INSTALLED - Model explainability\n",
      "  matplotlib          : INSTALLED - Visualization\n",
      "  seaborn             : INSTALLED - Statistical visualization\n",
      "\n",
      "All core dependencies installed!\n"
     ]
    }
   ],
   "source": [
    "# Check core dependencies\n",
    "required_packages = {\n",
    "    \"pandas\": \"Data manipulation\",\n",
    "    \"numpy\": \"Numerical computing\",\n",
    "    \"sklearn\": \"Machine learning (scikit-learn)\",  # Import name is sklearn, not scikit-learn\n",
    "    \"xgboost\": \"Gradient boosting\",\n",
    "    \"lightgbm\": \"Gradient boosting\",\n",
    "    \"optuna\": \"Hyperparameter tuning\",\n",
    "    \"mlflow\": \"Experiment tracking\",\n",
    "    \"shap\": \"Model explainability\",\n",
    "    \"matplotlib\": \"Visualization\",\n",
    "    \"seaborn\": \"Statistical visualization\",\n",
    "}\n",
    "\n",
    "print(\"Checking core dependencies...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "missing_packages = []\n",
    "for package, description in required_packages.items():\n",
    "    try:\n",
    "        __import__(package)\n",
    "        print(f\"  {package:20s}: INSTALLED - {description}\")\n",
    "    except ImportError:\n",
    "        print(f\"  {package:20s}: MISSING - {description}\")\n",
    "        missing_packages.append(package)\n",
    "\n",
    "if missing_packages:\n",
    "    print(f\"\\nMissing packages: {', '.join(missing_packages)}\")\n",
    "    print(\"Install with: pip install -e .\")\n",
    "else:\n",
    "    print(\"\\nAll core dependencies installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T11:47:38.231330Z",
     "iopub.status.busy": "2025-12-01T11:47:38.230725Z",
     "iopub.status.idle": "2025-12-01T11:47:38.242265Z",
     "shell.execute_reply": "2025-12-01T11:47:38.239910Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking data access...\n",
      "================================================================================\n",
      "Raw data file: NOT FOUND at C:\\Users\\tiwar\\OneDrive - The University of Melbourne\\Desktop\\New folder\\data\\raw\\telco_data_28_11_2025.csv\n",
      "Please download the Telco Customer Churn dataset and place it in data/raw/\n",
      "Processed data directory: Will be created when running Phase 1\n"
     ]
    }
   ],
   "source": [
    "# Check if data file exists\n",
    "raw_data_path = PROJECT_ROOT / \"data\" / \"raw\" / \"telco_data_28_11_2025.csv\"\n",
    "\n",
    "print(\"Checking data access...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if raw_data_path.exists():\n",
    "    print(f\"Raw data file: FOUND at {raw_data_path}\")\n",
    "\n",
    "    # Try to load a sample\n",
    "    try:\n",
    "        import pandas as pd\n",
    "\n",
    "        df_sample = pd.read_csv(raw_data_path, nrows=5)\n",
    "        print(\"Data file is readable\")\n",
    "        print(f\"Sample columns: {list(df_sample.columns)[:5]}...\")\n",
    "        print(f\"Sample shape (first 5 rows): {df_sample.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading data file: {e}\")\n",
    "else:\n",
    "    print(f\"Raw data file: NOT FOUND at {raw_data_path}\")\n",
    "    print(\"Please download the Telco Customer Churn dataset and place it in data/raw/\")\n",
    "\n",
    "# Check processed data\n",
    "processed_dir = PROJECT_ROOT / \"data\" / \"processed\"\n",
    "if processed_dir.exists():\n",
    "    timestamp_dirs = [d for d in processed_dir.iterdir() if d.is_dir()]\n",
    "    if timestamp_dirs:\n",
    "        latest = max(timestamp_dirs, key=lambda p: p.name)\n",
    "        print(f\"Processed data: FOUND (latest: {latest.name})\")\n",
    "    else:\n",
    "        print(\"Processed data: No processed snapshots found\")\n",
    "else:\n",
    "    print(\"Processed data directory: Will be created when running Phase 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test Project Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T11:47:38.246215Z",
     "iopub.status.busy": "2025-12-01T11:47:38.245658Z",
     "iopub.status.idle": "2025-12-01T11:47:44.123411Z",
     "shell.execute_reply": "2025-12-01T11:47:44.120121Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing project module imports...\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  src.data.ingestion            : OK\n",
      "  src.data.validation           : OK\n",
      "  src.data.eda                  : OK\n",
      "  src.features.pipeline         : OK\n",
      "  src.features.transformers     : OK\n",
      "  src.features.store            : OK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  src.models.baseline           : OK\n",
      "  src.models.trainer            : OK\n",
      "  src.models.evaluation         : OK\n",
      "  src.models.explainability     : OK\n",
      "\n",
      "All project modules import successfully!\n"
     ]
    }
   ],
   "source": [
    "# Test importing project modules\n",
    "print(\"Testing project module imports...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "modules_to_test = [\n",
    "    \"src.data.ingestion\",\n",
    "    \"src.data.validation\",\n",
    "    \"src.data.eda\",\n",
    "    \"src.features.pipeline\",\n",
    "    \"src.features.transformers\",\n",
    "    \"src.features.store\",\n",
    "    \"src.models.baseline\",\n",
    "    \"src.models.trainer\",\n",
    "    \"src.models.evaluation\",\n",
    "    \"src.models.explainability\",\n",
    "]\n",
    "\n",
    "failed_imports = []\n",
    "for module_name in modules_to_test:\n",
    "    try:\n",
    "        __import__(module_name)\n",
    "        print(f\"  {module_name:30s}: OK\")\n",
    "    except ImportError as e:\n",
    "        print(f\"  {module_name:30s}: FAILED - {str(e)[:50]}\")\n",
    "        failed_imports.append(module_name)\n",
    "\n",
    "if failed_imports:\n",
    "    print(f\"\\nFailed imports: {len(failed_imports)}\")\n",
    "    print(\"Make sure you've installed the project: pip install -e .\")\n",
    "else:\n",
    "    print(\"\\nAll project modules import successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Verify Development Tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T11:47:44.128512Z",
     "iopub.status.busy": "2025-12-01T11:47:44.127732Z",
     "iopub.status.idle": "2025-12-01T11:47:49.936370Z",
     "shell.execute_reply": "2025-12-01T11:47:49.934702Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking development tools...\n",
      "================================================================================\n",
      "  ruff                : INSTALLED - Linting (ruff 0.14.6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  black               : INSTALLED - Code formatting (black, 25.11.0 (compiled: yes))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  mypy                : INSTALLED - Type checking (mypy 1.18.2 (compiled: yes))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  pytest              : INSTALLED - Testing (pytest 8.4.1)\n",
      "\n",
      "All development tools available!\n"
     ]
    }
   ],
   "source": [
    "# Check development tools\n",
    "import subprocess\n",
    "\n",
    "dev_tools = {\n",
    "    \"ruff\": \"Linting\",\n",
    "    \"black\": \"Code formatting\",\n",
    "    \"mypy\": \"Type checking\",\n",
    "    \"pytest\": \"Testing\",\n",
    "}\n",
    "\n",
    "print(\"Checking development tools...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "missing_tools = []\n",
    "for tool, description in dev_tools.items():\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [tool, \"--version\"],\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            timeout=30,  # Increased timeout\n",
    "        )\n",
    "        if result.returncode == 0:\n",
    "            version = result.stdout.strip().split(\"\\n\")[0]\n",
    "            print(f\"  {tool:20s}: INSTALLED - {description} ({version})\")\n",
    "        else:\n",
    "            print(f\"  {tool:20s}: NOT FOUND - {description}\")\n",
    "            missing_tools.append(tool)\n",
    "    except subprocess.TimeoutExpired:\n",
    "        # If timeout, try to check if it's installed via import\n",
    "        try:\n",
    "            if tool == \"pytest\":\n",
    "                import pytest\n",
    "\n",
    "                print(f\"  {tool:20s}: INSTALLED - {description} (pytest {pytest.__version__})\")\n",
    "            else:\n",
    "                print(f\"  {tool:20s}: TIMEOUT - {description} (assuming installed)\")\n",
    "        except ImportError:\n",
    "            print(f\"  {tool:20s}: NOT FOUND - {description}\")\n",
    "            missing_tools.append(tool)\n",
    "    except (FileNotFoundError, ImportError):\n",
    "        print(f\"  {tool:20s}: NOT FOUND - {description}\")\n",
    "        missing_tools.append(tool)\n",
    "\n",
    "if missing_tools:\n",
    "    print(f\"\\nMissing tools: {', '.join(missing_tools)}\")\n",
    "    print(\"Install with: pip install -e .[dev]\")\n",
    "else:\n",
    "    print(\"\\nAll development tools available!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Setup Summary\n",
    "\n",
    "### Next Steps:\n",
    "1. If any dependencies are missing, install them:\n",
    "   ```bash\n",
    "   pip install -e .\n",
    "   pip install -e .[dev]  # For development tools\n",
    "   pip install -e .[eda]  # For EDA tools (jupyter, etc.)\n",
    "   ```\n",
    "\n",
    "2. Download the Telco Customer Churn dataset to `data/raw/telco_data_28_11_2025.csv`\n",
    "\n",
    "3. Run Phase 1 notebook to begin data exploration:\n",
    "   - `notebooks/phase1_eda.ipynb`\n",
    "\n",
    "4. Execute Phase 1 script to generate processed data:\n",
    "   ```bash\n",
    "   python scripts/run_phase1_data_intake.py\n",
    "   ```\n",
    "\n",
    "### Project Structure:\n",
    "- `src/`: Core application code\n",
    "- `notebooks/`: Exploratory analysis notebooks\n",
    "- `scripts/`: CLI utilities for pipeline execution\n",
    "- `tests/`: Unit and integration tests\n",
    "- `configs/`: Configuration files\n",
    "- `docs/`: Documentation\n",
    "\n",
    "### Getting Help:\n",
    "- See `README.md` for project overview\n",
    "- See `docs/roadmap.md` for phase details\n",
    "- See `docs/architecture.md` for system design\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
